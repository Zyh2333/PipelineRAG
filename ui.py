import streamlit as st
import os
from pathlib import Path
from nodes.document.pdf_processor import PDFProcessorNode
from nodes.document.text_splitter import TextSplitterNode
from nodes.embedding.text_embedding import TextEmbeddingNode
from nodes.vector.vector_store_node import VectorStoreNode
from nodes.llm.openai import GPT3Node
from nodes.prompt.prompt_node import PromptNode
from pipelines.base import Pipeline

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ–‡æ¡£é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ“š",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'processed_files' not in st.session_state:
    st.session_state.processed_files = []
if 'indexing_pipeline' not in st.session_state:
    st.session_state.indexing_pipeline = None
if 'query_pipeline' not in st.session_state:
    st.session_state.query_pipeline = None
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'question_asked' not in st.session_state:
    st.session_state.question_asked = False


def initialize_indexing_pipeline():
    """åˆå§‹åŒ–æ–‡æ¡£å¤„ç†pipeline"""
    pipeline = Pipeline()

    pdf_processor = PDFProcessorNode()
    text_splitter = TextSplitterNode(
        chunk_size=512,
        chunk_overlap=50,
    )
    embedding_node = TextEmbeddingNode(
        model_name="paraphrase-multilingual-MiniLM-L12-v2"
    )
    vector_store = VectorStoreNode(
        index_file_path="data/faiss_index.bin",
        mapping_file_path="data/text_mapping.pkl",
        dimension=384
    )

    pipeline.add_node(component=pdf_processor, name="PDFProcessor", inputs=["File"])
    pipeline.add_node(component=text_splitter, name="TextSplitter", inputs=["PDFProcessor"])
    pipeline.add_node(component=embedding_node, name="TextEmbedding", inputs=["TextSplitter"])
    pipeline.add_node(component=vector_store, name="VectorStore", inputs=["TextEmbedding"])

    return pipeline


def initialize_query_pipeline():
    """åˆå§‹åŒ–é—®ç­”pipeline"""
    pipeline = Pipeline()

    embedding_node = TextEmbeddingNode(
        model_name="paraphrase-multilingual-MiniLM-L12-v2",
    )
    vector_store = VectorStoreNode(
        index_file_path="data/faiss_index.bin",
        mapping_file_path="data/text_mapping.pkl",
        dimension=384,
    )
    prompt_node = PromptNode()
    gpt_node = GPT3Node(
        api_key="Bearer fk220173-cGW7fQeV2jkHUDlbePBEd1YyhXVWEFnh",
    )

    pipeline.add_node(component=embedding_node, name="TextEmbedding", inputs=["Query"])
    pipeline.add_node(component=vector_store, name="VectorRetrieval", inputs=["TextEmbedding"])
    pipeline.add_node(component=prompt_node, name="PromptBuilder", inputs=["VectorRetrieval"])
    pipeline.add_node(component=gpt_node, name="GPTNode", inputs=["PromptBuilder"])

    return pipeline


def main():
    st.title("ğŸ“š æ™ºèƒ½æ–‡æ¡£é—®ç­”ç³»ç»Ÿ")

    # åˆ›å»ºæ•°æ®ç›®å½•
    os.makedirs("data", exist_ok=True)

    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")

        # åˆ›å»ºæ–‡ä»¶ä¸Šä¼ å™¨
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ PDFæ–‡ä»¶",
            type=['pdf'],
            accept_multiple_files=True
        )

        if uploaded_files:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            pdf_files = []
            for uploaded_file in uploaded_files:
                file_path = f"doc/{uploaded_file.name}"
                os.makedirs("doc", exist_ok=True)

                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                pdf_files.append(file_path)

            st.session_state.processed_files = pdf_files
            st.success(f"ä¸Šä¼ äº† {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")

        # æ˜¾ç¤ºä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨
        if st.session_state.processed_files:
            st.write("å·²ä¸Šä¼ çš„æ–‡ä»¶:")
            for file in st.session_state.processed_files:
                st.text(f"ğŸ“„ {Path(file).name}")

        # å¤„ç†æ–‡æ¡£æŒ‰é’®
        if st.button("å¤„ç†æ–‡æ¡£", disabled=not st.session_state.processed_files):
            with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
                try:
                    if not st.session_state.indexing_pipeline:
                        st.session_state.indexing_pipeline = initialize_indexing_pipeline()
                    st.session_state.indexing_pipeline.run(file_paths=st.session_state.processed_files)
                    st.success("æ–‡æ¡£å¤„ç†å®Œæˆï¼")

                    # åˆå§‹åŒ–æŸ¥è¯¢pipeline
                    if not st.session_state.query_pipeline:
                        st.session_state.query_pipeline = initialize_query_pipeline()
                except Exception as e:
                    st.error(f"å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")

    # ä¸»ç•Œé¢
    st.header("ğŸ’¬ é—®ç­”ç³»ç»Ÿ")

    # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†æ–‡æ¡£
    if not os.path.exists("data/faiss_index.bin"):
        st.warning("è¯·å…ˆä¸Šä¼ å¹¶å¤„ç†æ–‡æ¡£åå†å¼€å§‹æé—®")
        return

    # é—®ç­”åŒºåŸŸ
    if not st.session_state.query_pipeline:
        st.session_state.query_pipeline = initialize_query_pipeline()

    # æ˜¾ç¤ºèŠå¤©å†å²
    chat_container = st.container()
    with chat_container:
        for qa in st.session_state.chat_history:
            st.write(f"ğŸ‘¤ **é—®é¢˜**: {qa['question']}")
            st.write(f"ğŸ¤– **å›ç­”**: {qa['answer']}")
            st.write("---")

    # é—®é¢˜è¾“å…¥åŒºåŸŸ
    with st.form(key='qa_form'):
        query = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜:", placeholder="ä¾‹å¦‚ï¼šäº§å“æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ")
        submit_button = st.form_submit_button("å‘é€é—®é¢˜")

        if submit_button and query:
            try:
                with st.spinner("AIæ€è€ƒä¸­..."):
                    result = st.session_state.query_pipeline.run(query=query)
                    answer = result.get('response', 'æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚')

                    # æ·»åŠ åˆ°èŠå¤©å†å²
                    st.session_state.chat_history.append({
                        'question': query,
                        'answer': answer
                    })

                st.rerun()

            except Exception as e:
                st.error(f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}")


if __name__ == "__main__":
    main()